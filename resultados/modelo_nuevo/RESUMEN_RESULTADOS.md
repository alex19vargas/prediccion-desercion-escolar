# ğŸ“Š Resumen de Resultados - Modelo Nuevo

**Fecha de generaciÃ³n:** 18 de octubre de 2025  
**Base de datos:** DesercionEscolarCompleta.xlsx (5000 registros, 34 columnas)  
**DistribuciÃ³n:** 84.44% No Desertores, 15.56% Desertores

---

## ğŸ¯ Modelos Entrenados (9 Total)

### ğŸ¥‡ Modelos con Rendimiento Perfecto (100% Accuracy)

1. **KNeighbors**
   - Accuracy: 100.00%
   - Precision: 100.00%
   - Recall: 100.00%
   - F1-Score: 100.00%
   - Mejor configuraciÃ³n: n_neighbors=3, weights='distance', metric='euclidean'
   - âœ… 0 Falsos Positivos, 0 Falsos Negativos

2. **SVM (Support Vector Machine)**
   - Accuracy: 100.00%
   - Precision: 100.00%
   - Recall: 100.00%
   - F1-Score: 100.00%
   - Mejor configuraciÃ³n: C=10, kernel='rbf', gamma='scale'
   - âœ… 0 Falsos Positivos, 0 Falsos Negativos

3. **Neural Network (MLP)**
   - Accuracy: 100.00%
   - Precision: 100.00%
   - Recall: 100.00%
   - F1-Score: 100.00%
   - Mejor configuraciÃ³n: hidden_layers=(50,50), activation='tanh', alpha=0.0001
   - âœ… 0 Falsos Positivos, 0 Falsos Negativos

---

### ğŸ¥ˆ Modelos con Excelente Rendimiento (>99%)

4. **Random Forest**
   - Accuracy: 99.27%
   - Precision: 99.26%
   - Recall: 99.27%
   - F1-Score: 99.26%
   - Mejor configuraciÃ³n: n_estimators=100, max_depth=None, min_samples_split=2
   - Errores: 3 FP, 8 FN

5. **Gradient Boosting**
   - Accuracy: 99.13%
   - Precision: 99.13%
   - Recall: 99.13%
   - F1-Score: 99.13%
   - Mejor configuraciÃ³n: n_estimators=200, learning_rate=0.1, max_depth=5
   - Errores: 5 FP, 8 FN

6. **Decision Tree**
   - Accuracy: 99.07%
   - Precision: 99.06%
   - Recall: 99.07%
   - F1-Score: 99.06%
   - Mejor configuraciÃ³n: max_depth=None, min_samples_split=2, min_samples_leaf=1
   - Errores: 5 FP, 9 FN

---

### ğŸ¥‰ Modelos con Muy Buen Rendimiento (~99%)

7. **Logistic Regression**
   - Accuracy: 98.87%
   - Precision: 98.87%
   - Recall: 98.87%
   - F1-Score: 98.87%
   - Mejor configuraciÃ³n: C=10, penalty='l1', solver='liblinear'
   - Errores: 9 FP, 8 FN

8. **AdaBoost**
   - Accuracy: 98.80%
   - Precision: 98.80%
   - Recall: 98.80%
   - F1-Score: 98.80%
   - Mejor configuraciÃ³n: n_estimators=50, learning_rate=0.5
   - Errores: 10 FP, 8 FN

---

### âš ï¸ Modelo con Rendimiento Moderado

9. **Naive Bayes**
   - Accuracy: 87.73%
   - Precision: 91.34%
   - Recall: 87.73%
   - F1-Score: 88.75%
   - Mejor configuraciÃ³n: var_smoothing=1e-09
   - Errores: 158 FP, 26 FN
   - **Nota:** Aunque tiene menor accuracy, detecta bien los casos de deserciÃ³n (recall=89% para desertores)

---

## ğŸ“ Archivos Generados

### Carpeta: `resultados/modelo_nuevo/`

#### ğŸ“¦ Modelos Entrenados (9 archivos .pkl)
- `logisticregression_model.pkl` (1.1 KB)
- `decisiontree_model.pkl` (6.7 KB)
- `randomforest_model.pkl` (956 KB)
- `gradientboosting_model.pkl` (1.0 MB)
- `adaboost_model.pkl` (29 KB)
- `kneighbors_model.pkl` (1.1 MB)
- `svm_model.pkl` (94 KB)
- `neuralnetwork_model.pkl` (153 KB)
- `naivebayes_model.pkl` (1.9 KB)

#### ğŸ“Š Matrices de ConfusiÃ³n (9 imÃ¡genes PNG)
- Una por cada modelo mostrando: Verdaderos Positivos, Falsos Positivos, Verdaderos Negativos, Falsos Negativos

#### ğŸ“ˆ GrÃ¡ficos de Rendimiento (14 imÃ¡genes PNG)
- **Curvas de Aprendizaje (9):** Muestran cÃ³mo mejora el modelo con mÃ¡s datos
- **Importancia de Variables (4):** Para RandomForest, GradientBoosting, DecisionTree, AdaBoost
- **ComparaciÃ³n General (1):** GrÃ¡fico de barras comparando todos los modelos

#### ğŸ“‹ MÃ©tricas (1 archivo CSV)
- `comparacion_modelos.csv`: Tabla con Accuracy, Precision, Recall y F1-Score de todos los modelos

---

## ğŸ“ InterpretaciÃ³n de Resultados

### Variables MÃ¡s Importantes (segÃºn Random Forest):
1. **Final_Grade** - CalificaciÃ³n final
2. **Grade_2** - CalificaciÃ³n del segundo perÃ­odo
3. **Grade_1** - CalificaciÃ³n del primer perÃ­odo
4. **Number_of_Absences** - NÃºmero de ausencias
5. **Number_of_Failures** - NÃºmero de reprobaciones

### RecomendaciÃ³n de Modelo para ProducciÃ³n:
Aunque **KNeighbors, SVM y Neural Network** tienen 100% de precisiÃ³n, recomiendo usar **Random Forest** o **Gradient Boosting** porque:
- âœ… Rendimiento excelente (>99%)
- âœ… MÃ¡s robustos ante nuevos datos
- âœ… Proporcionan importancia de variables
- âœ… Menos propensos a sobreajuste
- âœ… MÃ¡s interpretables

### Uso del Modelo:
```python
import joblib
import pandas as pd

# Cargar el modelo
modelo = joblib.load('resultados/modelo_nuevo/modelos/randomforest_model.pkl')

# Preparar datos nuevos (deben tener las mismas columnas que el entrenamiento)
X_nuevo = pd.DataFrame(...)

# Hacer predicciones
predicciones = modelo.predict(X_nuevo)
probabilidades = modelo.predict_proba(X_nuevo)

# 0 = No Desertor, 1 = Desertor
```

---

## ğŸ“ Notas TÃ©cnicas

- **DivisiÃ³n de datos:** 70% entrenamiento, 30% prueba
- **ValidaciÃ³n cruzada:** StratifiedKFold con 5 splits
- **OptimizaciÃ³n:** GridSearchCV para encontrar mejores hiperparÃ¡metros
- **Escalado:** StandardScaler aplicado a todas las variables
- **Variables categÃ³ricas:** Convertidas con pd.get_dummies()

---

## ğŸ”„ PrÃ³ximos Pasos

1. âœ… Comparar con `modelo_base` (base de datos original)
2. â³ Validar con datos reales del siguiente semestre
3. â³ Implementar sistema de alertas tempranas
4. â³ Integrar con aplicaciÃ³n web
5. â³ Crear dashboard interactivo
